{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df=pd.read_csv(\"cancer.csv\")\n",
    "df=df.drop('id',axis=1).drop('Unnamed: 32',axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['texture_mean']=np.sqrt(np.sqrt(np.sqrt(df['texture_mean'])))\n",
    "df['perimeter_mean']=np.log(np.log(np.log(df['perimeter_mean'])))\n",
    "df['smoothness_mean']=np.sqrt(np.sqrt(np.sqrt(df['smoothness_mean'])))\n",
    "df['compactness_mean']=np.log(df['compactness_mean'])\n",
    "df['symmetry_mean']=np.log(df['symmetry_mean'])\n",
    "df['fractal_dimension_mean']=np.log(np.sqrt(df['fractal_dimension_mean']))\n",
    "df['texture_se']=np.log(df['texture_se'])\n",
    "df['smoothness_se']=np.log(np.sqrt(df['smoothness_se']))\n",
    "df['area_se']=np.log(np.log(np.log(df['area_se'])))\n",
    "df['concave points_se']=np.sqrt(df['concave points_se'])\n",
    "df['symmetry_se']=np.log(np.sqrt(df['symmetry_se']))\n",
    "df['fractal_dimension_se']=np.log(np.sqrt(np.sqrt(df['fractal_dimension_se'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>1.339753</td>\n",
       "      <td>0.451593</td>\n",
       "      <td>0.765895</td>\n",
       "      <td>-1.281574</td>\n",
       "      <td>-1.419231</td>\n",
       "      <td>-1.270993</td>\n",
       "      <td>-0.099489</td>\n",
       "      <td>0.479970</td>\n",
       "      <td>-2.525807</td>\n",
       "      <td>0.125976</td>\n",
       "      <td>-1.752779</td>\n",
       "      <td>-1.271084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>1.432884</td>\n",
       "      <td>0.461915</td>\n",
       "      <td>0.734533</td>\n",
       "      <td>-2.542875</td>\n",
       "      <td>-1.708154</td>\n",
       "      <td>-1.435255</td>\n",
       "      <td>-0.309382</td>\n",
       "      <td>0.378307</td>\n",
       "      <td>-2.627150</td>\n",
       "      <td>0.115758</td>\n",
       "      <td>-2.138293</td>\n",
       "      <td>-1.411473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>1.465277</td>\n",
       "      <td>0.459061</td>\n",
       "      <td>0.758536</td>\n",
       "      <td>-1.833207</td>\n",
       "      <td>-1.575520</td>\n",
       "      <td>-1.406789</td>\n",
       "      <td>-0.239654</td>\n",
       "      <td>0.414572</td>\n",
       "      <td>-2.545652</td>\n",
       "      <td>0.143457</td>\n",
       "      <td>-1.897120</td>\n",
       "      <td>-1.347006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>1.457641</td>\n",
       "      <td>0.385587</td>\n",
       "      <td>0.783839</td>\n",
       "      <td>-1.259133</td>\n",
       "      <td>-1.348228</td>\n",
       "      <td>-1.164259</td>\n",
       "      <td>0.144966</td>\n",
       "      <td>0.178339</td>\n",
       "      <td>-2.349191</td>\n",
       "      <td>0.136638</td>\n",
       "      <td>-1.409798</td>\n",
       "      <td>-1.171921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>1.394982</td>\n",
       "      <td>0.464025</td>\n",
       "      <td>0.750175</td>\n",
       "      <td>-2.018911</td>\n",
       "      <td>-1.709811</td>\n",
       "      <td>-1.416552</td>\n",
       "      <td>-0.246796</td>\n",
       "      <td>0.415204</td>\n",
       "      <td>-2.233139</td>\n",
       "      <td>0.137295</td>\n",
       "      <td>-2.021066</td>\n",
       "      <td>-1.318894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  texture_mean  perimeter_mean  smoothness_mean  compactness_mean  \\\n",
       "0         M      1.339753        0.451593         0.765895         -1.281574   \n",
       "1         M      1.432884        0.461915         0.734533         -2.542875   \n",
       "2         M      1.465277        0.459061         0.758536         -1.833207   \n",
       "3         M      1.457641        0.385587         0.783839         -1.259133   \n",
       "4         M      1.394982        0.464025         0.750175         -2.018911   \n",
       "\n",
       "   symmetry_mean  fractal_dimension_mean  texture_se   area_se  smoothness_se  \\\n",
       "0      -1.419231               -1.270993   -0.099489  0.479970      -2.525807   \n",
       "1      -1.708154               -1.435255   -0.309382  0.378307      -2.627150   \n",
       "2      -1.575520               -1.406789   -0.239654  0.414572      -2.545652   \n",
       "3      -1.348228               -1.164259    0.144966  0.178339      -2.349191   \n",
       "4      -1.709811               -1.416552   -0.246796  0.415204      -2.233139   \n",
       "\n",
       "   concave points_se  symmetry_se  fractal_dimension_se  \n",
       "0           0.125976    -1.752779             -1.271084  \n",
       "1           0.115758    -2.138293             -1.411473  \n",
       "2           0.143457    -1.897120             -1.347006  \n",
       "3           0.136638    -1.409798             -1.171921  \n",
       "4           0.137295    -2.021066             -1.318894  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_drop=['radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst',\\\n",
    "        'concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst','radius_mean',\\\n",
    "        'concavity_se','perimeter_se','concavity_mean','area_mean','compactness_se','radius_se','concave points_mean']\n",
    "df=df.drop(f_drop,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>diagnosis_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  diagnosis_code\n",
       "0         M               1\n",
       "1         M               1\n",
       "2         M               1\n",
       "3         M               1\n",
       "4         M               1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_diagnosis=LabelEncoder()\n",
    "df['diagnosis_code']=le_diagnosis.fit_transform(df['diagnosis'])\n",
    "df[['diagnosis','diagnosis_code']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: diagnosis_code, dtype: int32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('diagnosis',axis=1,inplace=True)\n",
    "df['diagnosis_code'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    357\n",
       "1    212\n",
       "Name: diagnosis_code, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diagnosis_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2,f_classif\n",
    "x=df.drop(\"diagnosis_code\",axis=1)\n",
    "y=df['diagnosis_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestfeatures=SelectKBest(score_func=f_classif,k=3)\n",
    "fit=bestfeatures.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfscores=pd.DataFrame(fit.scores_)\n",
    "dfcolumns=pd.DataFrame(x.columns)\n",
    "featurescores=pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featurescores.columns=['Specs','Scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Specs      Scores\n",
      "0             texture_mean  126.842106\n",
      "1           perimeter_mean  658.322918\n",
      "2          smoothness_mean   86.789422\n",
      "3         compactness_mean  312.873240\n",
      "4            symmetry_mean   70.965034\n",
      "5   fractal_dimension_mean    0.252105\n",
      "6               texture_se    0.511491\n",
      "7                  area_se  532.617592\n",
      "8            smoothness_se    1.855606\n",
      "9        concave points_se  124.571606\n",
      "10             symmetry_se    1.671978\n",
      "11    fractal_dimension_se   16.078365\n"
     ]
    }
   ],
   "source": [
    "print(featurescores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Specs      Scores\n",
      "1         perimeter_mean  658.322918\n",
      "7                area_se  532.617592\n",
      "3       compactness_mean  312.873240\n",
      "0           texture_mean  126.842106\n",
      "9      concave points_se  124.571606\n",
      "2        smoothness_mean   86.789422\n",
      "4          symmetry_mean   70.965034\n",
      "11  fractal_dimension_se   16.078365\n",
      "8          smoothness_se    1.855606\n"
     ]
    }
   ],
   "source": [
    "df1=featurescores.nlargest(9,'Scores')\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data with 9 Input Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107  10]\n",
      " [  3  51]]\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['diagnosis_code','fractal_dimension_se','symmetry_se','texture_se'],axis=1)\n",
    "y=df.diagnosis_code\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=4)\n",
    "\n",
    "logmodel=LogisticRegression()\n",
    "logmodel.fit(x_train,y_train)\n",
    "\n",
    "predictions=logmodel.predict(x_test)\n",
    "\n",
    "r=confusion_matrix(y_test,predictions)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 92.39766081871345\n",
      "True Positive Rate (TPR) : 97.27272727272728\n",
      "True Negative Rate (TNR) : 83.60655737704919\n",
      "False Negative Rate (FNR) : 2.727272727272727\n",
      "False Positive Rate (FPR) : 16.39344262295082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94       117\n",
      "           1       0.84      0.94      0.89        54\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       171\n",
      "   macro avg       0.90      0.93      0.91       171\n",
      "weighted avg       0.93      0.92      0.93       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\",accuracy_score(y_test,predictions)*100)\n",
    "print(\"True Positive Rate (TPR) :\",(r[0][0]/(r[0][0]+r[1][0]))*100)\n",
    "print(\"True Negative Rate (TNR) :\",(r[1][1]/(r[1][1]+r[0][1]))*100)\n",
    "print(\"False Negative Rate (FNR) :\",(r[1][0]/(r[1][0]+r[0][0]))*100)\n",
    "print(\"False Positive Rate (FPR) :\",(r[0][1]/(r[0][1]+r[1][1]))*100)\n",
    "x1=(classification_report(y_test,predictions))\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data With 10 Input Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107  10]\n",
      " [  3  51]]\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['diagnosis_code','fractal_dimension_se','texture_se',],axis=1)\n",
    "y=df.diagnosis_code\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=4)\n",
    "\n",
    "logmodel=LogisticRegression()\n",
    "logmodel.fit(x_train,y_train)\n",
    "\n",
    "predictions=logmodel.predict(x_test)\n",
    "\n",
    "r=confusion_matrix(y_test,predictions)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 92.39766081871345\n",
      "True Positive Rate (TPR) : 97.27272727272728\n",
      "True Negative Rate (TNR) : 83.60655737704919\n",
      "False Negative Rate (FNR) : 2.727272727272727\n",
      "False Positive Rate (FPR) : 16.39344262295082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94       117\n",
      "           1       0.84      0.94      0.89        54\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       171\n",
      "   macro avg       0.90      0.93      0.91       171\n",
      "weighted avg       0.93      0.92      0.93       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\",accuracy_score(y_test,predictions)*100)\n",
    "print(\"True Positive Rate (TPR) :\",(r[0][0]/(r[0][0]+r[1][0]))*100)\n",
    "print(\"True Negative Rate (TNR) :\",(r[1][1]/(r[1][1]+r[0][1]))*100)\n",
    "print(\"False Negative Rate (FNR) :\",(r[1][0]/(r[1][0]+r[0][0]))*100)\n",
    "print(\"False Positive Rate (FPR) :\",(r[0][1]/(r[0][1]+r[1][1]))*100)\n",
    "x1=(classification_report(y_test,predictions))\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data With 11 Input Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[108   9]\n",
      " [  4  50]]\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['diagnosis_code','fractal_dimension_se'],axis=1)\n",
    "y=df.diagnosis_code\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=4)\n",
    "\n",
    "logmodel=LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)\n",
    "\n",
    "predictions=logmodel.predict(X_test)\n",
    "\n",
    "r=confusion_matrix(y_test,predictions)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 92.39766081871345\n",
      "True Positive Rate (TPR) : 96.42857142857143\n",
      "True Negative Rate (TNR) : 84.7457627118644\n",
      "False Negative Rate (FNR) : 3.571428571428571\n",
      "False Positive Rate (FPR) : 15.254237288135593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94       117\n",
      "           1       0.85      0.93      0.88        54\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       171\n",
      "   macro avg       0.91      0.92      0.91       171\n",
      "weighted avg       0.93      0.92      0.92       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\",accuracy_score(y_test,predictions)*100)\n",
    "print(\"True Positive Rate (TPR) :\",(r[0][0]/(r[0][0]+r[1][0]))*100)\n",
    "print(\"True Negative Rate (TNR) :\",(r[1][1]/(r[1][1]+r[0][1]))*100)\n",
    "print(\"False Negative Rate (FNR) :\",(r[1][0]/(r[1][0]+r[0][0]))*100)\n",
    "print(\"False Positive Rate (FPR) :\",(r[0][1]/(r[0][1]+r[1][1]))*100)\n",
    "x1=(classification_report(y_test,predictions))\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data With 12 Input Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107  10]\n",
      " [  4  50]]\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['diagnosis_code'],axis=1)\n",
    "y=df.diagnosis_code\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=4)\n",
    "\n",
    "logmodel=LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)\n",
    "\n",
    "predictions=logmodel.predict(X_test)\n",
    "\n",
    "r=confusion_matrix(y_test,predictions)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 91.81286549707602\n",
      "True Positive Rate (TPR) : 96.3963963963964\n",
      "True Negative Rate (TNR) : 83.33333333333334\n",
      "False Negative Rate (FNR) : 3.6036036036036037\n",
      "False Positive Rate (FPR) : 16.666666666666664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.94       117\n",
      "           1       0.83      0.93      0.88        54\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       171\n",
      "   macro avg       0.90      0.92      0.91       171\n",
      "weighted avg       0.92      0.92      0.92       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\",accuracy_score(y_test,predictions)*100)\n",
    "print(\"True Positive Rate (TPR) :\",(r[0][0]/(r[0][0]+r[1][0]))*100)\n",
    "print(\"True Negative Rate (TNR) :\",(r[1][1]/(r[1][1]+r[0][1]))*100)\n",
    "print(\"False Negative Rate (FNR) :\",(r[1][0]/(r[1][0]+r[0][0]))*100)\n",
    "print(\"False Positive Rate (FPR) :\",(r[0][1]/(r[0][1]+r[1][1]))*100)\n",
    "x1=(classification_report(y_test,predictions))\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "df=pd.read_csv(\"cancer.csv\")\n",
    "df=df.drop(['id','Unnamed: 32'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['texture_mean']=np.sqrt(np.sqrt(np.sqrt(df['texture_mean'])))\n",
    "df['perimeter_mean']=np.log(np.log(np.log(df['perimeter_mean'])))\n",
    "df['smoothness_mean']=np.sqrt(np.sqrt(np.sqrt(df['smoothness_mean'])))\n",
    "df['compactness_mean']=np.log(df['compactness_mean'])\n",
    "df['symmetry_mean']=np.log(df['symmetry_mean'])\n",
    "df['fractal_dimension_mean']=np.log(np.sqrt(df['fractal_dimension_mean']))\n",
    "df['texture_se']=np.log(df['texture_se'])\n",
    "df['smoothness_se']=np.log(np.sqrt(df['smoothness_se']))\n",
    "df['area_se']=np.log(np.log(np.log(df['area_se'])))\n",
    "df['concave points_se']=np.sqrt(df['concave points_se'])\n",
    "df['symmetry_se']=np.log(np.sqrt(df['symmetry_se']))\n",
    "df['fractal_dimension_se']=np.log(np.sqrt(np.sqrt(df['fractal_dimension_se'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_drop=['radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst',\\\n",
    "        'concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst','radius_mean',\\\n",
    "        'concavity_se','perimeter_se','concavity_mean','area_mean','compactness_se','radius_se','concave points_mean']\n",
    "df=df.drop(f_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>diagnosis_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  diagnosis_code\n",
       "0         M               1\n",
       "1         M               1\n",
       "2         M               1\n",
       "3         M               1\n",
       "4         M               1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_diagnosis=LabelEncoder()\n",
    "df['diagnosis_code']=le_diagnosis.fit_transform(df['diagnosis'])\n",
    "df[['diagnosis','diagnosis_code']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: diagnosis_code, dtype: int32"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('diagnosis',axis=1,inplace=True)\n",
    "df['diagnosis_code'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(['diagnosis_code'],axis=1)\n",
    "Y=df['diagnosis_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1\n",
       "0  1\n",
       "1  1\n",
       "2  1\n",
       "3  1\n",
       "4  1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosis_code=pd.get_dummies(df['diagnosis_code'],drop_first=True)\n",
    "diagnosis_code.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    357\n",
       "1    212\n",
       "Name: diagnosis_code, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.diagnosis_code.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data With 9 Input Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[104  13]\n",
      " [  7  47]]\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['diagnosis_code','fractal_dimension_se','texture_se',],axis=1)\n",
    "y=df.diagnosis_code\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=4)\n",
    "\n",
    "classifier_entropy=DecisionTreeClassifier(criterion='entropy',random_state=42,max_depth=3)\n",
    "\n",
    "classifier_entropy.fit(x_train,y_train)\n",
    "\n",
    "predictions=classifier_entropy.predict(x_test)\n",
    "\n",
    "r=confusion_matrix(y_test,predictions)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 88.30409356725146\n",
      "True Positive Rate (TPR) : 93.69369369369369\n",
      "True Negative Rate (TNR) : 78.33333333333333\n",
      "False Negative Rate (FNR) : 6.306306306306306\n",
      "False Positive Rate (FPR) : 21.666666666666668\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91       117\n",
      "           1       0.78      0.87      0.82        54\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       171\n",
      "   macro avg       0.86      0.88      0.87       171\n",
      "weighted avg       0.89      0.88      0.88       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\",accuracy_score(y_test,predictions)*100)\n",
    "print(\"True Positive Rate (TPR) :\",(r[0][0]/(r[0][0]+r[1][0]))*100)\n",
    "print(\"True Negative Rate (TNR) :\",(r[1][1]/(r[1][1]+r[0][1]))*100)\n",
    "print(\"False Negative Rate (FNR) :\",(r[1][0]/(r[1][0]+r[0][0]))*100)\n",
    "print(\"False Positive Rate (FPR) :\",(r[0][1]/(r[0][1]+r[1][1]))*100)\n",
    "x1=(classification_report(y_test,predictions))\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data With 10 Input Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[104  13]\n",
      " [  7  47]]\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['diagnosis_code','fractal_dimension_se','texture_se',],axis=1)\n",
    "y=df.diagnosis_code\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=4)\n",
    "\n",
    "classifier_entropy=DecisionTreeClassifier(criterion='entropy',random_state=42,max_depth=3)\n",
    "\n",
    "classifier_entropy.fit(x_train,y_train)\n",
    "\n",
    "predictions=classifier_entropy.predict(x_test)\n",
    "\n",
    "r=confusion_matrix(y_test,predictions)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 88.30409356725146\n",
      "True Positive Rate (TPR) : 93.69369369369369\n",
      "True Negative Rate (TNR) : 78.33333333333333\n",
      "False Negative Rate (FNR) : 6.306306306306306\n",
      "False Positive Rate (FPR) : 21.666666666666668\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91       117\n",
      "           1       0.78      0.87      0.82        54\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       171\n",
      "   macro avg       0.86      0.88      0.87       171\n",
      "weighted avg       0.89      0.88      0.88       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\",accuracy_score(y_test,predictions)*100)\n",
    "print(\"True Positive Rate (TPR) :\",(r[0][0]/(r[0][0]+r[1][0]))*100)\n",
    "print(\"True Negative Rate (TNR) :\",(r[1][1]/(r[1][1]+r[0][1]))*100)\n",
    "print(\"False Negative Rate (FNR) :\",(r[1][0]/(r[1][0]+r[0][0]))*100)\n",
    "print(\"False Positive Rate (FPR) :\",(r[0][1]/(r[0][1]+r[1][1]))*100)\n",
    "x1=(classification_report(y_test,predictions))\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data With 11 Input Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[104  13]\n",
      " [  7  47]]\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['diagnosis_code','fractal_dimension_se'],axis=1)\n",
    "y=df.diagnosis_code\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=4)\n",
    "\n",
    "classifier_entropy=DecisionTreeClassifier(criterion='entropy',random_state=42,max_depth=3)\n",
    "\n",
    "classifier_entropy.fit(x_train,y_train)\n",
    "\n",
    "predictions=classifier_entropy.predict(x_test)\n",
    "\n",
    "r=confusion_matrix(y_test,predictions)\n",
    "print(r)# Train Data With 12 Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 88.30409356725146\n",
      "True Positive Rate (TPR) : 93.69369369369369\n",
      "True Negative Rate (TNR) : 78.33333333333333\n",
      "False Negative Rate (FNR) : 6.306306306306306\n",
      "False Positive Rate (FPR) : 21.666666666666668\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91       117\n",
      "           1       0.78      0.87      0.82        54\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       171\n",
      "   macro avg       0.86      0.88      0.87       171\n",
      "weighted avg       0.89      0.88      0.88       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\",accuracy_score(y_test,predictions)*100)\n",
    "print(\"True Positive Rate (TPR) :\",(r[0][0]/(r[0][0]+r[1][0]))*100)\n",
    "print(\"True Negative Rate (TNR) :\",(r[1][1]/(r[1][1]+r[0][1]))*100)\n",
    "print(\"False Negative Rate (FNR) :\",(r[1][0]/(r[1][0]+r[0][0]))*100)\n",
    "print(\"False Positive Rate (FPR) :\",(r[0][1]/(r[0][1]+r[1][1]))*100)\n",
    "x1=(classification_report(y_test,predictions))\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data With 12 Input Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[105  12]\n",
      " [  7  47]]\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['diagnosis_code'],axis=1)\n",
    "y=df.diagnosis_code\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=4)\n",
    "\n",
    "classifier_entropy=DecisionTreeClassifier(criterion='entropy',random_state=42,max_depth=3)\n",
    "\n",
    "classifier_entropy.fit(x_train,y_train)\n",
    "\n",
    "predictions=classifier_entropy.predict(x_test)\n",
    "\n",
    "r=confusion_matrix(y_test,predictions)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 88.88888888888889\n",
      "True Positive Rate (TPR) : 93.75\n",
      "True Negative Rate (TNR) : 79.66101694915254\n",
      "False Negative Rate (FNR) : 6.25\n",
      "False Positive Rate (FPR) : 20.33898305084746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92       117\n",
      "           1       0.80      0.87      0.83        54\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       171\n",
      "   macro avg       0.87      0.88      0.87       171\n",
      "weighted avg       0.89      0.89      0.89       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\",accuracy_score(y_test,predictions)*100)\n",
    "print(\"True Positive Rate (TPR) :\",(r[0][0]/(r[0][0]+r[1][0]))*100)\n",
    "print(\"True Negative Rate (TNR) :\",(r[1][1]/(r[1][1]+r[0][1]))*100)\n",
    "print(\"False Negative Rate (FNR) :\",(r[1][0]/(r[1][0]+r[0][0]))*100)\n",
    "print(\"False Positive Rate (FPR) :\",(r[0][1]/(r[0][1]+r[1][1]))*100)\n",
    "x1=(classification_report(y_test,predictions))\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df=pd.read_csv('Cancer.csv')\n",
    "df=df.drop(['Unnamed: 32','id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['texture_mean']=np.sqrt(np.sqrt(np.sqrt(df['texture_mean'])))\n",
    "df['perimeter_mean']=np.log(np.log(np.log(df['perimeter_mean'])))\n",
    "df['smoothness_mean']=np.sqrt(np.sqrt(np.sqrt(df['smoothness_mean'])))\n",
    "df['compactness_mean']=np.log(df['compactness_mean'])\n",
    "df['symmetry_mean']=np.log(df['symmetry_mean'])\n",
    "df['fractal_dimension_mean']=np.log(np.sqrt(df['fractal_dimension_mean']))\n",
    "df['texture_se']=np.log(df['texture_se'])\n",
    "df['smoothness_se']=np.log(np.sqrt(df['smoothness_se']))\n",
    "df['area_se']=np.log(np.log(np.log(df['area_se'])))\n",
    "df['concave points_se']=np.sqrt(df['concave points_se'])\n",
    "df['symmetry_se']=np.log(np.sqrt(df['symmetry_se']))\n",
    "df['fractal_dimension_se']=np.log(np.sqrt(np.sqrt(df['fractal_dimension_se'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_drop=['radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst',\\\n",
    "        'concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst','radius_mean',\\\n",
    "        'concavity_se','perimeter_se','concavity_mean','area_mean','compactness_se','radius_se','concave points_mean']\n",
    "df=df.drop(f_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_diagnosis=LabelEncoder()\n",
    "df['diagnosis_code']=le_diagnosis.fit_transform(df['diagnosis'])\n",
    "df.drop('diagnosis',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data with 9 Input Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107  10]\n",
      " [  1  53]]\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['diagnosis_code','fractal_dimension_se','symmetry_se','texture_se'],axis=1)\n",
    "y=df.diagnosis_code\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=4,test_size=0.3)\n",
    "\n",
    "sc_x=StandardScaler()\n",
    "x_train=sc_x.fit_transform(x_train)\n",
    "x_test=sc_x.fit_transform(x_test)\n",
    "\n",
    "classifier=KNeighborsClassifier(n_neighbors=7,p=2,metric='euclidean')\n",
    "classifier.fit(x_train,y_train)\n",
    "\n",
    "predictions=classifier.predict(x_test)\n",
    "\n",
    "r=confusion_matrix(y_test,predictions)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 93.56725146198829\n",
      "True Positive Rate (TPR) : 99.07407407407408\n",
      "True Negative Rate (TNR) : 84.12698412698413\n",
      "False Negative Rate (FNR) : 0.9259259259259258\n",
      "False Positive Rate (FPR) : 15.873015873015872\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       117\n",
      "           1       0.84      0.98      0.91        54\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       171\n",
      "   macro avg       0.92      0.95      0.93       171\n",
      "weighted avg       0.94      0.94      0.94       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\",accuracy_score(y_test,predictions)*100)\n",
    "print(\"True Positive Rate (TPR) :\",(r[0][0]/(r[0][0]+r[1][0]))*100)\n",
    "print(\"True Negative Rate (TNR) :\",(r[1][1]/(r[1][1]+r[0][1]))*100)\n",
    "print(\"False Negative Rate (FNR) :\",(r[1][0]/(r[1][0]+r[0][0]))*100)\n",
    "print(\"False Positive Rate (FPR) :\",(r[0][1]/(r[0][1]+r[1][1]))*100)\n",
    "x1=(classification_report(y_test,predictions))\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data with 10 Input Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[106  11]\n",
      " [  2  52]]\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['diagnosis_code','fractal_dimension_se','texture_se',],axis=1)\n",
    "y=df.diagnosis_code\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=4,test_size=0.3)\n",
    "\n",
    "sc_x=StandardScaler()\n",
    "x_train=sc_x.fit_transform(x_train)\n",
    "x_test=sc_x.fit_transform(x_test)\n",
    "\n",
    "classifier=KNeighborsClassifier(n_neighbors=7,p=2,metric='euclidean')\n",
    "classifier.fit(x_train,y_train)\n",
    "\n",
    "predictions=classifier.predict(x_test)\n",
    "\n",
    "r=confusion_matrix(y_test,predictions)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 92.39766081871345\n",
      "True Positive Rate (TPR) : 98.14814814814815\n",
      "True Negative Rate (TNR) : 82.53968253968253\n",
      "False Negative Rate (FNR) : 1.8518518518518516\n",
      "False Positive Rate (FPR) : 17.46031746031746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94       117\n",
      "           1       0.83      0.96      0.89        54\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       171\n",
      "   macro avg       0.90      0.93      0.92       171\n",
      "weighted avg       0.93      0.92      0.93       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\",accuracy_score(y_test,predictions)*100)\n",
    "print(\"True Positive Rate (TPR) :\",(r[0][0]/(r[0][0]+r[1][0]))*100)\n",
    "print(\"True Negative Rate (TNR) :\",(r[1][1]/(r[1][1]+r[0][1]))*100)\n",
    "print(\"False Negative Rate (FNR) :\",(r[1][0]/(r[1][0]+r[0][0]))*100)\n",
    "print(\"False Positive Rate (FPR) :\",(r[0][1]/(r[0][1]+r[1][1]))*100)\n",
    "x1=(classification_report(y_test,predictions))\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data with 11 Input Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[108   9]\n",
      " [  3  51]]\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['diagnosis_code','fractal_dimension_se'],axis=1)\n",
    "y=df.diagnosis_code\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=4,test_size=0.3)\n",
    "\n",
    "sc_x=StandardScaler()\n",
    "x_train=sc_x.fit_transform(x_train)\n",
    "x_test=sc_x.fit_transform(x_test)\n",
    "\n",
    "classifier=KNeighborsClassifier(n_neighbors=7,p=2,metric='euclidean')\n",
    "classifier.fit(x_train,y_train)\n",
    "\n",
    "predictions=classifier.predict(x_test)\n",
    "\n",
    "r=confusion_matrix(y_test,predictions)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 92.98245614035088\n",
      "True Positive Rate (TPR) : 97.2972972972973\n",
      "True Negative Rate (TNR) : 85.0\n",
      "False Negative Rate (FNR) : 2.7027027027027026\n",
      "False Positive Rate (FPR) : 15.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.95       117\n",
      "           1       0.85      0.94      0.89        54\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       171\n",
      "   macro avg       0.91      0.93      0.92       171\n",
      "weighted avg       0.93      0.93      0.93       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\",accuracy_score(y_test,predictions)*100)\n",
    "print(\"True Positive Rate (TPR) :\",(r[0][0]/(r[0][0]+r[1][0]))*100)\n",
    "print(\"True Negative Rate (TNR) :\",(r[1][1]/(r[1][1]+r[0][1]))*100)\n",
    "print(\"False Negative Rate (FNR) :\",(r[1][0]/(r[1][0]+r[0][0]))*100)\n",
    "print(\"False Positive Rate (FPR) :\",(r[0][1]/(r[0][1]+r[1][1]))*100)\n",
    "x1=(classification_report(y_test,predictions))\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data with 12 Input Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[110   7]\n",
      " [  3  51]]\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['diagnosis_code'],axis=1)\n",
    "y=df.diagnosis_code\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=4,test_size=0.3)\n",
    "\n",
    "sc_x=StandardScaler()\n",
    "x_train=sc_x.fit_transform(x_train)\n",
    "x_test=sc_x.fit_transform(x_test)\n",
    "\n",
    "classifier=KNeighborsClassifier(n_neighbors=7,p=2,metric='euclidean')\n",
    "classifier.fit(x_train,y_train)\n",
    "\n",
    "predictions=classifier.predict(x_test)\n",
    "\n",
    "r=confusion_matrix(y_test,predictions)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 94.15204678362574\n",
      "True Positive Rate (TPR) : 97.34513274336283\n",
      "True Negative Rate (TNR) : 87.93103448275862\n",
      "False Negative Rate (FNR) : 2.6548672566371683\n",
      "False Positive Rate (FPR) : 12.068965517241379\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96       117\n",
      "           1       0.88      0.94      0.91        54\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       171\n",
      "   macro avg       0.93      0.94      0.93       171\n",
      "weighted avg       0.94      0.94      0.94       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\",accuracy_score(y_test,predictions)*100)\n",
    "print(\"True Positive Rate (TPR) :\",(r[0][0]/(r[0][0]+r[1][0]))*100)\n",
    "print(\"True Negative Rate (TNR) :\",(r[1][1]/(r[1][1]+r[0][1]))*100)\n",
    "print(\"False Negative Rate (FNR) :\",(r[1][0]/(r[1][0]+r[0][0]))*100)\n",
    "print(\"False Positive Rate (FPR) :\",(r[0][1]/(r[0][1]+r[1][1]))*100)\n",
    "x1=(classification_report(y_test,predictions))\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data with 9 Input Features (When n_neighbors=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[108   9]\n",
      " [  2  52]]\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['diagnosis_code','fractal_dimension_se','symmetry_se','texture_se'],axis=1)\n",
    "y=df.diagnosis_code\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=4,test_size=0.3)\n",
    "\n",
    "sc_x=StandardScaler()\n",
    "x_train=sc_x.fit_transform(x_train)\n",
    "x_test=sc_x.fit_transform(x_test)\n",
    "\n",
    "classifier=KNeighborsClassifier(n_neighbors=9,p=2,metric='euclidean')\n",
    "classifier.fit(x_train,y_train)\n",
    "\n",
    "predictions=classifier.predict(x_test)\n",
    "\n",
    "r=confusion_matrix(y_test,predictions)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 93.56725146198829\n",
      "True Positive Rate (TPR) : 98.18181818181819\n",
      "True Negative Rate (TNR) : 85.24590163934425\n",
      "False Negative Rate (FNR) : 1.8181818181818181\n",
      "False Positive Rate (FPR) : 14.754098360655737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95       117\n",
      "           1       0.85      0.96      0.90        54\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       171\n",
      "   macro avg       0.92      0.94      0.93       171\n",
      "weighted avg       0.94      0.94      0.94       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\",accuracy_score(y_test,predictions)*100)\n",
    "print(\"True Positive Rate (TPR) :\",(r[0][0]/(r[0][0]+r[1][0]))*100)\n",
    "print(\"True Negative Rate (TNR) :\",(r[1][1]/(r[1][1]+r[0][1]))*100)\n",
    "print(\"False Negative Rate (FNR) :\",(r[1][0]/(r[1][0]+r[0][0]))*100)\n",
    "print(\"False Positive Rate (FPR) :\",(r[0][1]/(r[0][1]+r[1][1]))*100)\n",
    "x1=(classification_report(y_test,predictions))\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data with 9 Input Features (When n_neighbors=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[110   7]\n",
      " [  0  54]]\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['diagnosis_code','fractal_dimension_se','symmetry_se','texture_se'],axis=1)\n",
    "y=df.diagnosis_code\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=4,test_size=0.3)\n",
    "\n",
    "sc_x=StandardScaler()\n",
    "x_train=sc_x.fit_transform(x_train)\n",
    "x_test=sc_x.fit_transform(x_test)\n",
    "\n",
    "classifier=KNeighborsClassifier(n_neighbors=11,p=2,metric='euclidean')\n",
    "classifier.fit(x_train,y_train)\n",
    "\n",
    "predictions=classifier.predict(x_test)\n",
    "\n",
    "r=confusion_matrix(y_test,predictions)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 95.90643274853801\n",
      "True Positive Rate (TPR) : 100.0\n",
      "True Negative Rate (TNR) : 88.52459016393442\n",
      "False Negative Rate (FNR) : 0.0\n",
      "False Positive Rate (FPR) : 11.475409836065573\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       117\n",
      "           1       0.89      1.00      0.94        54\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       171\n",
      "   macro avg       0.94      0.97      0.95       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\",accuracy_score(y_test,predictions)*100)\n",
    "print(\"True Positive Rate (TPR) :\",(r[0][0]/(r[0][0]+r[1][0]))*100)\n",
    "print(\"True Negative Rate (TNR) :\",(r[1][1]/(r[1][1]+r[0][1]))*100)\n",
    "print(\"False Negative Rate (FNR) :\",(r[1][0]/(r[1][0]+r[0][0]))*100)\n",
    "print(\"False Positive Rate (FPR) :\",(r[0][1]/(r[0][1]+r[1][1]))*100)\n",
    "x1=(classification_report(y_test,predictions))\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cancer.csv')\n",
    "df.drop(['Unnamed: 32','id'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['texture_mean']=np.sqrt(np.sqrt(np.sqrt(df['texture_mean'])))\n",
    "df['perimeter_mean']=np.log(np.log(np.log(df['perimeter_mean'])))\n",
    "df['smoothness_mean']=np.sqrt(np.sqrt(np.sqrt(df['smoothness_mean'])))\n",
    "df['compactness_mean']=np.log(df['compactness_mean'])\n",
    "df['symmetry_mean']=np.log(df['symmetry_mean'])\n",
    "df['fractal_dimension_mean']=np.log(np.sqrt(df['fractal_dimension_mean']))\n",
    "df['texture_se']=np.log(df['texture_se'])\n",
    "df['smoothness_se']=np.log(np.sqrt(df['smoothness_se']))\n",
    "df['area_se']=np.log(np.log(np.log(df['area_se'])))\n",
    "df['concave points_se']=np.sqrt(df['concave points_se'])\n",
    "df['symmetry_se']=np.log(np.sqrt(df['symmetry_se']))\n",
    "df['fractal_dimension_se']=np.log(np.sqrt(np.sqrt(df['fractal_dimension_se'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>diagnosis_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  diagnosis_code\n",
       "0         M               1\n",
       "1         M               1\n",
       "2         M               1\n",
       "3         M               1\n",
       "4         M               1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_diagnosis=LabelEncoder()\n",
    "df['diagnosis_code']=le_diagnosis.fit_transform(df['diagnosis'])\n",
    "df[['diagnosis','diagnosis_code']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: diagnosis_code, dtype: int32"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('diagnosis',axis=1,inplace=True)\n",
    "df['diagnosis_code'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_drop=['radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst',\\\n",
    "        'concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst','radius_mean',\\\n",
    "        'concavity_se','perimeter_se','concavity_mean','area_mean','compactness_se','radius_se','concave points_mean']\n",
    "df=df.drop(f_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data with 9 Input Featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[105  12]\n",
      " [  2  52]]\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['diagnosis_code','fractal_dimension_se','symmetry_se','texture_se'],axis=1)\n",
    "y=df.diagnosis_code\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=4,test_size=0.3)\n",
    "\n",
    "model=GaussianNB()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "r=confusion_matrix(y_test,predictions)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 91.81286549707602\n",
      "True Positive Rate (TPR) : 98.13084112149532\n",
      "True Negative Rate (TNR) : 81.25\n",
      "False Negative Rate (FNR) : 1.8691588785046727\n",
      "False Positive Rate (FPR) : 18.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94       117\n",
      "           1       0.81      0.96      0.88        54\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       171\n",
      "   macro avg       0.90      0.93      0.91       171\n",
      "weighted avg       0.93      0.92      0.92       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\",accuracy_score(y_test,predictions)*100)\n",
    "print(\"True Positive Rate (TPR) :\",(r[0][0]/(r[0][0]+r[1][0]))*100)\n",
    "print(\"True Negative Rate (TNR) :\",(r[1][1]/(r[1][1]+r[0][1]))*100)\n",
    "print(\"False Negative Rate (FNR) :\",(r[1][0]/(r[1][0]+r[0][0]))*100)\n",
    "print(\"False Positive Rate (FPR) :\",(r[0][1]/(r[0][1]+r[1][1]))*100)\n",
    "x1=(classification_report(y_test,predictions))\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data with 10 Input Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[106  11]\n",
      " [  2  52]]\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['diagnosis_code','fractal_dimension_se','texture_se',],axis=1)\n",
    "y=df.diagnosis_code\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=4,test_size=0.3)\n",
    "\n",
    "model=GaussianNB()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "r=confusion_matrix(y_test,predictions)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 92.39766081871345\n",
      "True Positive Rate (TPR) : 98.14814814814815\n",
      "True Negative Rate (TNR) : 82.53968253968253\n",
      "False Negative Rate (FNR) : 1.8518518518518516\n",
      "False Positive Rate (FPR) : 17.46031746031746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94       117\n",
      "           1       0.83      0.96      0.89        54\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       171\n",
      "   macro avg       0.90      0.93      0.92       171\n",
      "weighted avg       0.93      0.92      0.93       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\",accuracy_score(y_test,predictions)*100)\n",
    "print(\"True Positive Rate (TPR) :\",(r[0][0]/(r[0][0]+r[1][0]))*100)\n",
    "print(\"True Negative Rate (TNR) :\",(r[1][1]/(r[1][1]+r[0][1]))*100)\n",
    "print(\"False Negative Rate (FNR) :\",(r[1][0]/(r[1][0]+r[0][0]))*100)\n",
    "print(\"False Positive Rate (FPR) :\",(r[0][1]/(r[0][1]+r[1][1]))*100)\n",
    "x1=(classification_report(y_test,predictions))\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data with 11 Input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[106  11]\n",
      " [  2  52]]\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['diagnosis_code','fractal_dimension_se'],axis=1)\n",
    "y=df.diagnosis_code\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=4,test_size=0.3)\n",
    "\n",
    "model=GaussianNB()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "r=confusion_matrix(y_test,predictions)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 92.39766081871345\n",
      "True Positive Rate (TPR) : 98.14814814814815\n",
      "True Negative Rate (TNR) : 82.53968253968253\n",
      "False Negative Rate (FNR) : 1.8518518518518516\n",
      "False Positive Rate (FPR) : 17.46031746031746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94       117\n",
      "           1       0.83      0.96      0.89        54\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       171\n",
      "   macro avg       0.90      0.93      0.92       171\n",
      "weighted avg       0.93      0.92      0.93       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\",accuracy_score(y_test,predictions)*100)\n",
    "print(\"True Positive Rate (TPR) :\",(r[0][0]/(r[0][0]+r[1][0]))*100)\n",
    "print(\"True Negative Rate (TNR) :\",(r[1][1]/(r[1][1]+r[0][1]))*100)\n",
    "print(\"False Negative Rate (FNR) :\",(r[1][0]/(r[1][0]+r[0][0]))*100)\n",
    "print(\"False Positive Rate (FPR) :\",(r[0][1]/(r[0][1]+r[1][1]))*100)\n",
    "x1=(classification_report(y_test,predictions))\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data with 12 Input Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[105  12]\n",
      " [  2  52]]\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['diagnosis_code'],axis=1)\n",
    "y=df.diagnosis_code\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=4,test_size=0.3)\n",
    "\n",
    "model=GaussianNB()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "r=confusion_matrix(y_test,predictions)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 91.81286549707602\n",
      "True Positive Rate (TPR) : 98.13084112149532\n",
      "True Negative Rate (TNR) : 81.25\n",
      "False Negative Rate (FNR) : 1.8691588785046727\n",
      "False Positive Rate (FPR) : 18.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94       117\n",
      "           1       0.81      0.96      0.88        54\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       171\n",
      "   macro avg       0.90      0.93      0.91       171\n",
      "weighted avg       0.93      0.92      0.92       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\",accuracy_score(y_test,predictions)*100)\n",
    "print(\"True Positive Rate (TPR) :\",(r[0][0]/(r[0][0]+r[1][0]))*100)\n",
    "print(\"True Negative Rate (TNR) :\",(r[1][1]/(r[1][1]+r[0][1]))*100)\n",
    "print(\"False Negative Rate (FNR) :\",(r[1][0]/(r[1][0]+r[0][0]))*100)\n",
    "print(\"False Positive Rate (FPR) :\",(r[0][1]/(r[0][1]+r[1][1]))*100)\n",
    "x1=(classification_report(y_test,predictions))\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Cancer.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['Unnamed: 32','id'],inplace=True,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VOTING TECHNIQUE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['texture_mean']=np.sqrt(np.sqrt(np.sqrt(df['texture_mean'])))\n",
    "df['perimeter_mean']=np.log(np.log(np.log(df['perimeter_mean'])))\n",
    "df['smoothness_mean']=np.sqrt(np.sqrt(np.sqrt(df['smoothness_mean'])))\n",
    "df['compactness_mean']=np.log(df['compactness_mean'])\n",
    "df['symmetry_mean']=np.log(df['symmetry_mean'])\n",
    "df['fractal_dimension_mean']=np.log(np.sqrt(df['fractal_dimension_mean']))\n",
    "df['texture_se']=np.log(df['texture_se'])\n",
    "df['smoothness_se']=np.log(np.sqrt(df['smoothness_se']))\n",
    "df['area_se']=np.log(np.log(np.log(df['area_se'])))\n",
    "df['concave points_se']=np.sqrt(df['concave points_se'])\n",
    "df['symmetry_se']=np.log(np.sqrt(df['symmetry_se']))\n",
    "df['fractal_dimension_se']=np.log(np.sqrt(np.sqrt(df['fractal_dimension_se'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_drop=['radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst',\\\n",
    "        'concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst','radius_mean',\\\n",
    "        'concavity_se','perimeter_se','concavity_mean','area_mean','compactness_se','radius_se','concave points_mean']\n",
    "df=df.drop(f_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>diagnosis_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  diagnosis_code\n",
       "0         M               1\n",
       "1         M               1\n",
       "2         M               1\n",
       "3         M               1\n",
       "4         M               1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_make=LabelEncoder()\n",
    "df[\"diagnosis_code\"]=lb_make.fit_transform(df[\"diagnosis\"])\n",
    "df[[\"diagnosis\",\"diagnosis_code\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>diagnosis_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.339753</td>\n",
       "      <td>0.451593</td>\n",
       "      <td>0.765895</td>\n",
       "      <td>-1.281574</td>\n",
       "      <td>-1.419231</td>\n",
       "      <td>-1.270993</td>\n",
       "      <td>-0.099489</td>\n",
       "      <td>0.479970</td>\n",
       "      <td>-2.525807</td>\n",
       "      <td>0.125976</td>\n",
       "      <td>-1.752779</td>\n",
       "      <td>-1.271084</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.432884</td>\n",
       "      <td>0.461915</td>\n",
       "      <td>0.734533</td>\n",
       "      <td>-2.542875</td>\n",
       "      <td>-1.708154</td>\n",
       "      <td>-1.435255</td>\n",
       "      <td>-0.309382</td>\n",
       "      <td>0.378307</td>\n",
       "      <td>-2.627150</td>\n",
       "      <td>0.115758</td>\n",
       "      <td>-2.138293</td>\n",
       "      <td>-1.411473</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.465277</td>\n",
       "      <td>0.459061</td>\n",
       "      <td>0.758536</td>\n",
       "      <td>-1.833207</td>\n",
       "      <td>-1.575520</td>\n",
       "      <td>-1.406789</td>\n",
       "      <td>-0.239654</td>\n",
       "      <td>0.414572</td>\n",
       "      <td>-2.545652</td>\n",
       "      <td>0.143457</td>\n",
       "      <td>-1.897120</td>\n",
       "      <td>-1.347006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.457641</td>\n",
       "      <td>0.385587</td>\n",
       "      <td>0.783839</td>\n",
       "      <td>-1.259133</td>\n",
       "      <td>-1.348228</td>\n",
       "      <td>-1.164259</td>\n",
       "      <td>0.144966</td>\n",
       "      <td>0.178339</td>\n",
       "      <td>-2.349191</td>\n",
       "      <td>0.136638</td>\n",
       "      <td>-1.409798</td>\n",
       "      <td>-1.171921</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.394982</td>\n",
       "      <td>0.464025</td>\n",
       "      <td>0.750175</td>\n",
       "      <td>-2.018911</td>\n",
       "      <td>-1.709811</td>\n",
       "      <td>-1.416552</td>\n",
       "      <td>-0.246796</td>\n",
       "      <td>0.415204</td>\n",
       "      <td>-2.233139</td>\n",
       "      <td>0.137295</td>\n",
       "      <td>-2.021066</td>\n",
       "      <td>-1.318894</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   texture_mean  perimeter_mean  smoothness_mean  compactness_mean  \\\n",
       "0      1.339753        0.451593         0.765895         -1.281574   \n",
       "1      1.432884        0.461915         0.734533         -2.542875   \n",
       "2      1.465277        0.459061         0.758536         -1.833207   \n",
       "3      1.457641        0.385587         0.783839         -1.259133   \n",
       "4      1.394982        0.464025         0.750175         -2.018911   \n",
       "\n",
       "   symmetry_mean  fractal_dimension_mean  texture_se   area_se  smoothness_se  \\\n",
       "0      -1.419231               -1.270993   -0.099489  0.479970      -2.525807   \n",
       "1      -1.708154               -1.435255   -0.309382  0.378307      -2.627150   \n",
       "2      -1.575520               -1.406789   -0.239654  0.414572      -2.545652   \n",
       "3      -1.348228               -1.164259    0.144966  0.178339      -2.349191   \n",
       "4      -1.709811               -1.416552   -0.246796  0.415204      -2.233139   \n",
       "\n",
       "   concave points_se  symmetry_se  fractal_dimension_se  diagnosis_code  \n",
       "0           0.125976    -1.752779             -1.271084               1  \n",
       "1           0.115758    -2.138293             -1.411473               1  \n",
       "2           0.143457    -1.897120             -1.347006               1  \n",
       "3           0.136638    -1.409798             -1.171921               1  \n",
       "4           0.137295    -2.021066             -1.318894               1  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop('diagnosis',axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107  10]\n",
      " [  3  51]]\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['diagnosis_code','fractal_dimension_se','symmetry_se','texture_se'],axis=1)\n",
    "y=df.diagnosis_code\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=4)\n",
    "\n",
    "logmodel=LogisticRegression()\n",
    "logmodel.fit(x_train,y_train)\n",
    "\n",
    "predictions=logmodel.predict(x_test)\n",
    "\n",
    "r=confusion_matrix(y_test,predictions)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 92.39766081871345\n",
      "True Positive Rate (TPR) : 97.27272727272728\n",
      "True Negative Rate (TNR) : 83.60655737704919\n",
      "False Negative Rate (FNR) : 2.727272727272727\n",
      "False Positive Rate (FPR) : 16.39344262295082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94       117\n",
      "           1       0.84      0.94      0.89        54\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       171\n",
      "   macro avg       0.90      0.93      0.91       171\n",
      "weighted avg       0.93      0.92      0.93       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\",accuracy_score(y_test,predictions)*100)\n",
    "print(\"True Positive Rate (TPR) :\",(r[0][0]/(r[0][0]+r[1][0]))*100)\n",
    "print(\"True Negative Rate (TNR) :\",(r[1][1]/(r[1][1]+r[0][1]))*100)\n",
    "print(\"False Negative Rate (FNR) :\",(r[1][0]/(r[1][0]+r[0][0]))*100)\n",
    "print(\"False Positive Rate (FPR) :\",(r[0][1]/(r[0][1]+r[1][1]))*100)\n",
    "x1=(classification_report(y_test,predictions))\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[105  12]\n",
      " [  7  47]]\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['diagnosis_code'],axis=1)\n",
    "y=df.diagnosis_code\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=4)\n",
    "\n",
    "classifier_entropy=DecisionTreeClassifier(criterion='entropy',random_state=42,max_depth=3)\n",
    "\n",
    "classifier_entropy.fit(x_train,y_train)\n",
    "\n",
    "predictions=classifier_entropy.predict(x_test)\n",
    "\n",
    "r=confusion_matrix(y_test,predictions)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 88.88888888888889\n",
      "True Positive Rate (TPR) : 93.75\n",
      "True Negative Rate (TNR) : 79.66101694915254\n",
      "False Negative Rate (FNR) : 6.25\n",
      "False Positive Rate (FPR) : 20.33898305084746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92       117\n",
      "           1       0.80      0.87      0.83        54\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       171\n",
      "   macro avg       0.87      0.88      0.87       171\n",
      "weighted avg       0.89      0.89      0.89       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\",accuracy_score(y_test,predictions)*100)\n",
    "print(\"True Positive Rate (TPR) :\",(r[0][0]/(r[0][0]+r[1][0]))*100)\n",
    "print(\"True Negative Rate (TNR) :\",(r[1][1]/(r[1][1]+r[0][1]))*100)\n",
    "print(\"False Negative Rate (FNR) :\",(r[1][0]/(r[1][0]+r[0][0]))*100)\n",
    "print(\"False Positive Rate (FPR) :\",(r[0][1]/(r[0][1]+r[1][1]))*100)\n",
    "x1=(classification_report(y_test,predictions))\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[110   7]\n",
      " [  0  54]]\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['diagnosis_code','fractal_dimension_se','symmetry_se','texture_se'],axis=1)\n",
    "y=df.diagnosis_code\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=4,test_size=0.3)\n",
    "\n",
    "sc_x=StandardScaler()\n",
    "x_train=sc_x.fit_transform(x_train)\n",
    "x_test=sc_x.fit_transform(x_test)\n",
    "\n",
    "classifier=KNeighborsClassifier(n_neighbors=11,p=2,metric='euclidean')\n",
    "classifier.fit(x_train,y_train)\n",
    "\n",
    "predictions=classifier.predict(x_test)\n",
    "\n",
    "r=confusion_matrix(y_test,predictions)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 95.90643274853801\n",
      "True Positive Rate (TPR) : 100.0\n",
      "True Negative Rate (TNR) : 88.52459016393442\n",
      "False Negative Rate (FNR) : 0.0\n",
      "False Positive Rate (FPR) : 11.475409836065573\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       117\n",
      "           1       0.89      1.00      0.94        54\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       171\n",
      "   macro avg       0.94      0.97      0.95       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\",accuracy_score(y_test,predictions)*100)\n",
    "print(\"True Positive Rate (TPR) :\",(r[0][0]/(r[0][0]+r[1][0]))*100)\n",
    "print(\"True Negative Rate (TNR) :\",(r[1][1]/(r[1][1]+r[0][1]))*100)\n",
    "print(\"False Negative Rate (FNR) :\",(r[1][0]/(r[1][0]+r[0][0]))*100)\n",
    "print(\"False Positive Rate (FPR) :\",(r[0][1]/(r[0][1]+r[1][1]))*100)\n",
    "x1=(classification_report(y_test,predictions))\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Baye's Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[106  11]\n",
      " [  2  52]]\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['diagnosis_code','fractal_dimension_se','texture_se',],axis=1)\n",
    "y=df.diagnosis_code\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=4,test_size=0.3)\n",
    "\n",
    "model=GaussianNB()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "r=confusion_matrix(y_test,predictions)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 92.39766081871345\n",
      "True Positive Rate (TPR) : 98.14814814814815\n",
      "True Negative Rate (TNR) : 82.53968253968253\n",
      "False Negative Rate (FNR) : 1.8518518518518516\n",
      "False Positive Rate (FPR) : 17.46031746031746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94       117\n",
      "           1       0.83      0.96      0.89        54\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       171\n",
      "   macro avg       0.90      0.93      0.92       171\n",
      "weighted avg       0.93      0.92      0.93       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\",accuracy_score(y_test,predictions)*100)\n",
    "print(\"True Positive Rate (TPR) :\",(r[0][0]/(r[0][0]+r[1][0]))*100)\n",
    "print(\"True Negative Rate (TNR) :\",(r[1][1]/(r[1][1]+r[0][1]))*100)\n",
    "print(\"False Negative Rate (FNR) :\",(r[1][0]/(r[1][0]+r[0][0]))*100)\n",
    "print(\"False Positive Rate (FPR) :\",(r[0][1]/(r[0][1]+r[1][1]))*100)\n",
    "x1=(classification_report(y_test,predictions))\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.4404761904762\n"
     ]
    }
   ],
   "source": [
    "X=df.drop(\"diagnosis_code\",axis=1)\n",
    "Y=df[\"diagnosis_code\"]\n",
    "\n",
    "seed=7\n",
    "num_trees=100\n",
    "max_features=3\n",
    "kfold=model_selection.KFold(n_splits=10,random_state=seed)\n",
    "model=rfc(n_estimators=num_trees,max_features=max_features)\n",
    "results=model_selection.cross_val_score(model,X,Y,cv=kfold)\n",
    "print(results.mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(\"diagnosis_code\",axis=1)\n",
    "Y=df[\"diagnosis_code\"]\n",
    "\n",
    "seed=7\n",
    "kfold=model_selection.KFold(n_splits=10,random_state=seed)\n",
    "estimators=[]\n",
    "model1=LogisticRegression()\n",
    "estimators.append(('logistic',model1))\n",
    "model2=DecisionTreeClassifier()\n",
    "estimators.append(('dect',model2))\n",
    "model3=KNeighborsClassifier()\n",
    "estimators.append(('knn',model3))\n",
    "model4=GaussianNB()\n",
    "estimators.append(('nb',model4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.86466165413533\n"
     ]
    }
   ],
   "source": [
    "ensemble=VotingClassifier(estimators)\n",
    "results=model_selection.cross_val_score(ensemble,X,Y,cv=kfold)\n",
    "print(results.mean()*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
